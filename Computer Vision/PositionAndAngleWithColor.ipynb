{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to255(num, val):\n",
    "    x = (num*255)//val\n",
    "    return x\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "boundaries = [\n",
    "        ([to255(20,360), to255(40,100), to255(60,100)], [to255(65,360), to255(100,100), to255(100,100)]),     #AMARILLO\n",
    "        ([to255(100,360), to255(35,100), to255(40,100)], [to255(160,360), to255(100,100), to255(100,100)]),   #AZUL\n",
    "        ([to255(10,360), to255(50,100), to255(55,100)], [to255(35,360), to255(98,100), to255(98,100)]),       #NARANJA\n",
    "        ([to255(0,360), to255(55,100), to255(50,100)], [to255(10,360), to255(100,100), to255(80,100)]),       #ROJO\n",
    "        ([to255(60,360), to255(30,100), to255(10,100)], [to255(120,360), to255(100,100), to255(100,100)]),    #VERDE\n",
    "        ([to255(180,360), to255(0,100), to255(0,100)], [to255(240,360), to255(70,100), to255(70,100)]),       #MORADO\n",
    "        ([to255(200,360), to255(20,100), to255(75,100)], [to255(360,360), to255(100,100), to255(100,100)]),   #ROSA\n",
    "        ]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def display(img, cmap = None):\n",
    "    fig = plt.figure(figsize = (12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap)\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_center(img, color):\n",
    "    global boundaries\n",
    "    centers = []\n",
    "    kernel = np.ones(shape = (4,4), dtype = np.uint8)\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    if color == \"orange\":\n",
    "        lower = np.array(boundaries[2][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[2][1], dtype = \"uint8\")\n",
    "    elif color == \"red\":\n",
    "        lower = np.array(boundaries[3][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[3][1], dtype = \"uint8\")\n",
    "    elif color == \"green\":\n",
    "        lower = np.array(boundaries[4][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[4][1], dtype = \"uint8\")\n",
    "    elif color == \"pink\":\n",
    "        lower = np.array(boundaries[6][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[6][1], dtype = \"uint8\")\n",
    "    elif color == \"purple\":\n",
    "        lower = np.array(boundaries[5][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[5][1], dtype = \"uint8\")\n",
    "    elif color == \"yellow\":\n",
    "        lower = np.array(boundaries[0][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[0][1], dtype = \"uint8\")\n",
    "    elif color == \"blue\":\n",
    "        lower = np.array(boundaries[1][0], dtype = \"uint8\")\n",
    "        upper = np.array(boundaries[1][1], dtype = \"uint8\")\n",
    "        \n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "    result = cv2.bitwise_and(rgb_img, rgb_img, mask = mask)\n",
    "    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    eroded = cv2.erode(thresh, kernel, iterations = 1)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations = 2)\n",
    "\n",
    "    image, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) != 0:\n",
    "        for i in contours:\n",
    "        \n",
    "            conv_hull = cv2.convexHull(i)\n",
    "\n",
    "            top    = tuple(conv_hull[conv_hull[:,:,1].argmin()][0])\n",
    "            bottom = tuple(conv_hull[conv_hull[:,:,1].argmax()][0])\n",
    "            left   = tuple(conv_hull[conv_hull[:,:,0].argmin()][0])\n",
    "            right  = tuple(conv_hull[conv_hull[:,:,0].argmax()][0])\n",
    "\n",
    "            cX = (left[0] + right[0]) // 2\n",
    "            cY = (top[1] + bottom[1]) // 2\n",
    "\n",
    "            centers.append((cX, cY))\n",
    "            \n",
    "        return centers\n",
    "    return None\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def min_distance(pt1, iterable):\n",
    "    x1 = pt1[0][0]\n",
    "    y1 = pt1[0][1]\n",
    "    min_distance = 10000000\n",
    "    min_center = 0\n",
    "    for i, (x2, y2) in enumerate(iterable):\n",
    "        distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_center = i \n",
    "    return min_center\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def draw_line(img, c1, c2):\n",
    "    min_c = min_distance(c1, c2)\n",
    "    cv2.line(img, c1[0], c2[min_c], color = 255, thickness = 2)\n",
    "    cv2.circle(img, c1[0], radius = 3, color = (0,255,0), thickness = -1)\n",
    "    cv2.circle(img, c2[min_c], radius = 3, color = (0,255,0), thickness = -1)\n",
    "    return img\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_robot_center(img, color1, color2):\n",
    "    centers1 = find_center(img, color1)\n",
    "    centers2 = find_center(img, color2)\n",
    "    \n",
    "    if centers1 != None and centers2 != None:\n",
    "        c1 = centers1[0]\n",
    "        c2 = centers2[min_distance(centers1, centers2)]\n",
    "        robot_center = (c1[0]+c2[0]) // 2, (c1[1]+c2[1]) // 2\n",
    "        return np.asarray([[c1], [c2], [robot_center]], dtype = np.float32)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for colors\n",
      "[[[269. 384.]]\n",
      "\n",
      " [[242. 387.]]\n",
      "\n",
      " [[255. 385.]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-309e72d8587c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mnextPts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevPts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#STATUS RETURNS 1 IF ANY FLOW HAS BEEN FOUND\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mgood_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnextPts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mgood_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevPts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "lk_params = dict(winSize = (200,200), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "#prevPts = [None]\n",
    "\n",
    "#while prevPts.any() == None:\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    print('looking for colors')\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prevPts = np.asarray(find_robot_center(prev_frame, \"red\", \"blue\"))\n",
    "    print(prevPts)\n",
    "\n",
    "\n",
    "mask = np.zeros_like(prev_frame) \n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame =  cap.read()\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)  #STATUS RETURNS 1 IF ANY FLOW HAS BEEN FOUND\n",
    "\n",
    "    good_new = nextPts[status == 1]\n",
    "    good_prev = prevPts[status == 1]\n",
    "\n",
    "    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "\n",
    "        x_new, y_new = new.ravel()            #TURNS MULTIDIMENSIONAL ARRAYS INTO A SINGLE DIMENTION ARRAY\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "\n",
    "        mask = cv2.line(mask, (x_new,y_new), (x_prev,y_prev), color = (0,255,0), thickness = 3)\n",
    "\n",
    "        frame = cv2.circle(frame, (x_new,y_new), radius = 8, color = (0,0,255), thickness = -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow(\"Tracking\", img)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"img = cv2.imread('C:/Users/jprr2/Videos/Logitech/LogiCapture/cancha.jpg')\n",
    "            \n",
    "cancha = img[280:680, 360:930, :]\n",
    "                 \n",
    "c1, c2, robot_center = find_robot_center(cancha, \"orange\", \"blue\")\n",
    "                 \n",
    "cv2.line(cancha, c1, c2, color = 255, thickness = 2)\n",
    "cv2.circle(cancha, robot_center, radius = 3, color = (0,255,0), thickness = -1)\n",
    "                 \n",
    "rgb_img = cv2.cvtColor(cancha, cv2.COLOR_BGR2RGB)\n",
    "                 \n",
    "display(rgb_img)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
